name: Sync Medium posts with local image download (optimized)

on:
  schedule:
    - cron: "0 8 * * 1" # Daily at 08:00 UTC
  workflow_dispatch:

permissions:
  contents: write

jobs:
  sync-medium:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout GitHub Pages blog repo
        uses: actions/checkout@v4

      - name: Install dependencies
        run: pip install feedparser markdownify requests beautifulsoup4

      - name: Parse RSS, convert new posts only, download images
        run: |
          python <<EOF
          import feedparser
          from markdownify import markdownify as md
          import os, re, requests, hashlib
          from collections import Counter
          import datetime
          from bs4 import BeautifulSoup
          from urllib.parse import urlparse

          feed_url = "https://medium.com/feed/@anandvk113"
          feed = feedparser.parse(feed_url)

          os.makedirs("_posts", exist_ok=True)
          os.makedirs("assets/images", exist_ok=True)

          existing_posts = set(os.listdir("_posts"))

          def download_image(url):
              try:
                  ext = os.path.splitext(urlparse(url).path)[-1]
                  if not ext or ext.lower() not in [".jpg", ".jpeg", ".png", ".webp", ".gif"]:
                      ext = ".png"
                  filename = hashlib.md5(url.encode()).hexdigest() + ext
                  local_path = f"assets/images/{filename}"
                  if not os.path.exists(local_path):
                      response = requests.get(url)
                      with open(local_path, "wb") as f:
                          f.write(response.content)
                  return "/" + local_path
              except Exception as e:
                  print(f"Failed to download {url}: {e}")
                  return url

          def get_top_tags(text, n=2):
              stopwords = set([
                  "the", "and", "to", "of", "in", "for", "a", "is", "on", "this", "with", "that", "as", "are",
                  "was", "it", "be", "at", "by", "an", "or", "from", "but", "we", "you", "they", "can", "not", "use",
                  "has", "have", "will", "which", "your", "all", "more", "our", "about", "any", "also", "if", "it's"
              ])
              words = re.findall(r'\b[a-zA-Z][a-zA-Z0-9-]*\b', text.lower())
              filtered = [w for w in words if w not in stopwords and len(w) > 2]
              freq = Counter(filtered)
              return list(dict(freq.most_common(n)).keys())

          for entry in feed.entries[:5]:
              title_text = entry.title
              title_slug = re.sub(r'[^\w\s-]', '', title_text).strip().lower().replace(' ', '-')
              date_obj = datetime.datetime(*entry.published_parsed[:6])
              date_str = date_obj.strftime("%Y-%m-%d %H:%M:%S +0530")
              file_slug = date_obj.date().isoformat() + "-" + title_slug + ".md"

              if file_slug in existing_posts:
                  print(f"Skipping already parsed post: {file_slug}")
                  continue

              content_html = entry.content[0].value
              soup = BeautifulSoup(content_html, "html.parser")

              image_urls = [img.get("src") for img in soup.find_all("img") if "medium.com" in (img.get("src") or "")]
              local_images = [download_image(url) for url in image_urls if url]
              for img, new_src in zip(soup.find_all("img"), local_images):
                  img["src"] = new_src

              markdown_body = md(str(soup))

              top_tags = get_top_tags(markdown_body, n=2)

              frontmatter = {
                  "title": title_text,
                  "date": date_str,
                  "categories": "[Blog, Medium]",
                  "tags": f"[{', '.join(top_tags)}]",
                  "author": "<author_id>",
                  "mermaid": "true",
                  "image": local_images[0] if local_images else "/assets/images/default.png",
                  "excerpt": f"\"{markdown_body.strip().splitlines()[0][:200]}...\""
              }

              with open(f"_posts/{file_slug}", "w", encoding="utf-8") as f:
                  f.write("---\n")
                  for key, value in frontmatter.items():
                      f.write(f"{key}: {value}\n")
                  f.write("---\n\n")
                  f.write(markdown_body)
          EOF

      - name: Commit and push
        run: |
          git config user.name "github-actions"
          git config user.email "actions@github.com"
          git add _posts assets/images
          git diff --cached --quiet || git commit -m "Auto-sync new Medium posts with images"
          git push
